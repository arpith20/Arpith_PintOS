			+--------------------+
			|       E0 253       |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Arpith K <arpith@live.com> or <arpith.k@csa.iisc.ernet.in>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the TAs,
>> or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while preparing
>> your submission, other than the Pintos documentation, course text, lecture
>> notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	
	threads/thread.c
	The following are the global variables declared in the implementation of
	the ALARM CLOCK feature.

		static bool initialised = false;
			A boolean variable to determine if at least one thread (idle
			thread) has been  initialized or not.

		static struct list alarm_blocked_threads;
			This is a list of all threads which are sleeping and waiting for
			the timer to expire

	threads/thread.h
	The following decelerations were made in `struct thread` to aid the
	implementation of ALARM CLOCK feature

		int64_t sleep_end_tick;
			Determines the time (ticks) until which the thread must be asleep. This
			value is calculated in the thread_sleep function.

		struct list_elem alarmsleepemem;
			This is the list element of the thread which is intended to be
			sleeping. This element is pushed by the thread_sleep function to
			alarm_blocked_threads list.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

	When the timer_sleep() function is called, the input is validated to check
	if it is greater than 0.

	If true, then `thread_sleep(int64_t start_time, int64_t
	no_of_ticks_to_sleep)` function is called. This takes in two arguments,
	start ticks and no of ticks to sleep. The value of ticks until which the
	thread must be asleep is calculated and the result is stored in that
	thread's `sleep_end_tick` data member. The thread is then pushed to the
	`alarm_blocked_threads` list and then blocked.

	If the initial condition is not validated, the input argument to
	thread_sleep is considered invalid and just ignored.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

	Only operations that are NOT computationally intensive are performed by
	the timer interrupt handler (`timer_interrupt`). Such operation include
	looping through list of blocked threads and unblocking operation.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

	To prevent race conditions, interrupts are disabled before any
	modifications to the list is made. This prevents multiple threads from
	modifying the `alarm_blocked_threads` list simultaneously and hence
	avoiding any possibility of race conditions.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

	Race conditions occur only when multiple threads try to modify a shared
	variable simultaneously. Such accesses are not allowed and thus race
	condition is avoided.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	It is imperative to minimize the amount of time spent in the interrupt
	handler. Maintaining the list of only the threads that are sleeping avoids
	the task of looping through all the threads in the system and thus saving
	some valuable time.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	threads/synch.c
		struct semaphore_elem
		{
			.....
			int priority;
		};
		The `struct semaphore_elem` was modified to include a variable
		variable to store the priority of the semaphore

	threads/sync.h
	The following data members were added to `struct lock` to aid the
	implementation of Priority scheduling

		int priority;
			This stores the priority of the thread currently holding the lock.

		struct list_elem lock_holder_elem;
			There exists a list of all locks that a thread holds named `struct
			list thread_locks` under `struct thread`. `lock_holder_elem` is
			list element of that list structure.

	threads/thread.h
	The following decelerations were made in `struct thread` to aid the
	implementation of priority scheduling feature

		int priority_original;
			This stores the value of priority of a thread as it was before
			receiving a donation from some other thread. This is required to
			reset it's priority once it releases all locks.

		struct list thread_locks;
			This is a list of all locks that the thread in question currently
			holds

		struct lock *required_lock;
			This is a pointer to the lock that the thread requires but does
			not currently have.


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

	The thread structure has been modified to include a new data member which
	stores the original value of it's priority in case it receives a priority
	from another thread. This is used to restore the value of priority once it
	releases the lock.

	I explicitly do not keep track of which thread donated the priority to the
	thread holding the lock. In terms of implementation, it is easier if I
	just ensure that the lock holder thread has the priority equal to that of
	a highest priority thread waiting on the former directly or indirectly (in
	nested form). When a thread tries to acquire a lock, I would iteratively
	propagate the the value of priority through the chain (for example see
	attached diagram) to ensure that the each thread holder in the chain has
	the highest priority.

	Please view the file named src/threads/DOC_B2.png to understand nested
	donation. In the example, let's say that we have three locks namely lock1,
	lock2 and lock3. Consider we have four threads t1(original priority 3),
	t2(10), t3(31) and t4(56) trying to acquire locks (refer diagram) in that
	order. The way this priority is donated iteratively, is shown.

	The diagram clearly shows how the thread t4 donates it's priority to t1.
	

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
	
	I am using the list_sort function on the waiting list to bring the thread
	with maximum priority to the front of the list just before the need to
	potentially wake it up arises.

	This ensures that the thread with highest priority us woken up.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

	There exists a need to donate the priority of the thread trying to acquire
	the lock to the one holding the lock whenever the later has lesser
	priority than the former. Failing to do this can cause the problem of
	priority inversion.

	The lock_acquire() function iteratively checks whether the thread trying
	to acquire the lock has higher priority than the one holding it. If so,
	the priority is donated. The iteration is required to handle the condition
	where in nested donation is required.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
	
	The following are the set to events that occur when lock_release is
	called.
	1.	lock->holder is set to NULL and the semaphore is upped.
	2.	Remove the lock from the list of locks that the thread holds. 
	3a. If the list at this point is empty (ie, the current thread holds no
        more locks), then restore the original priority of that thread.
    3b. Otherwise, set the priority of the thread holding that lock to that of
        the the thread with highest priority directly or indirectly waiting on
        it.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

	A race condition may occur only if multiple threads tries to modify the
	value of priority at the same time. This is not possible in my
	implementation. Any thread can modify their own priority only.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	During the design phase of this project a number of implementation options
	were considered. Finally a design which I felt would have the least
	overhead in terms of the number of additional data structures required and
	execution time of the code was implemented.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	threads/thread.h
	The thread structure was modified to include the following data members to
	aid the implementation of the advanced scheduler
		
		int recent_cpu;
			This data member tracks how much CPU a thread has used recently.

		int nice;
			Nice value is used to increase or decrease the effective priority
			of a thread. A positive value decreases the priority of the thread
			and causes it to give up some CPU time. A negative nice value has
			an opposite effect.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12	PLEASE VIEW /src/threads/DOC_C2_AdvancedScheduler.png
16					         OR
20		 /src/threads/DOC_C2_AdvancedScheduler.ods
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

	The scheduler specification does not indicate what happens when the
	priorities of two threads are equal. The values in the table can be
	different depending in the disambiguation protocol. I a simple round robin
	method has been employed by me.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

	Every time the timer interrupt handler executes, a function
	`mlfqs_computations()` is called. This function periodically performs a
	lot of computation using fixed point math for all threads in system. Such
	computations involve calculation of load_avg, recent_cpu and priorities at
	periodic intervals. While these computations are critical to the working,
	they might slightly deteriorate the performance in terms of responsiveness
	of the system.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

	If I had more time, I would have implemented abstractions for fixed point
	math which would have made the code more readable. Careful design was
	involved in implementing this project and I am happy with it for most
	parts.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
	
	I initially set out to implement inline functions to abstract math
	operations. Addition operation was implemented the prototype of which is
	`inline void fixed_point_real_increment(int *original, int value)`. 
	Due to lack of time, I did not implement abstractions for other math 
	operations. It was faster for me to implement it by manually performing
	the math as specified in the PintOS documentation (Section B.6) provided
	by Stanford.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

	As it might be apparent from my commit history in BitBucket, the task of
	PRIORITY SCHEDULING took the maximum time to implement. It also took a
	considerable amount of time to go through the documentation and understand
	the original PintOS code.

	The alarm clock was the easiest to implement of the three. In case of
	Advanced scheduler, while the implementation itself is straightforward,
	the task of understanding the BSD scheduler and all its quirks (*cough*
	Fixed-Point Real Arithmetic *cough*) was critical and took the majority of
	the time.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

	Definitely. After working on this project, I'll think twice before
	criticize Microsoft for all the bugs in their OS.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?